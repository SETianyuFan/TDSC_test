{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8635537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1          2           3           4           5   \\\n",
      "0    0.324081  0.113919  25.257430  221.713679  114.437756  254.385534   \n",
      "1    0.891822  0.182954  11.288263   61.700028   61.073726   74.330344   \n",
      "2    0.720290  0.183258  34.497578  188.245972  178.474088  267.226496   \n",
      "3    0.456011  0.197963  36.007521  181.890080  114.354711  213.114992   \n",
      "4    0.470130  0.136238  11.214203   82.313115   50.159745   91.005494   \n",
      "..        ...       ...        ...         ...         ...         ...   \n",
      "124  0.882767  0.241570  41.884166  173.383039  297.544955  212.150890   \n",
      "125  0.434268  0.222052  40.629555  182.973112  155.012903  140.292551   \n",
      "126  0.728373  0.234325  59.607648  254.380739  374.833296  216.187419   \n",
      "127  0.923890  0.250879  53.087549  211.606485  346.255686  232.137890   \n",
      "128  0.285109  0.063644  29.698362  466.631411  236.304888  124.679589   \n",
      "\n",
      "             6           7              8           9   ...             90  \\\n",
      "0    227.002203  257.841036  240990.958333   71.853275  ...   63643.622391   \n",
      "1     76.059187   84.386018   21055.583333   55.025449  ...   10451.597139   \n",
      "2    236.027541  267.378010  514978.041667  135.591649  ...  181798.797142   \n",
      "3    213.037555  224.879968  356036.875000   82.943896  ...  105909.772505   \n",
      "4     91.021975   92.027170   21881.666667   38.697874  ...    7976.190827   \n",
      "..          ...         ...            ...         ...  ...            ...   \n",
      "124  319.788993  335.667991  325165.916667  153.056835  ...  108284.067202   \n",
      "125  177.792013  327.636994   74159.791667   79.459396  ...   30290.331944   \n",
      "126  297.733102  379.639302  587162.833333  185.284174  ...  155723.897401   \n",
      "127  242.637590  361.222923  624815.291667  195.501108  ...  226544.750218   \n",
      "128  352.029828  352.031249   60754.875000  133.040739  ...   23338.312357   \n",
      "\n",
      "           91         92          93           94          95        96  \\\n",
      "0    1.372610   9.675509  272.384056  2036.111340   70.317967  0.213008   \n",
      "1    0.388782   6.292574  317.231717  1528.953732   72.489963  0.198064   \n",
      "2    0.793288  13.500740  316.198558  3705.150430   31.462178  0.093944   \n",
      "3    1.212655   8.603195  295.309807  1906.543115   73.848166  0.226567   \n",
      "4    1.004466   7.801711  274.192374  1510.303485   62.775739  0.216664   \n",
      "..        ...        ...         ...          ...         ...       ...   \n",
      "124  0.895092  11.014224  336.556278  3045.293090   47.328942  0.127006   \n",
      "125  0.490529   4.158788  313.231475  1060.257900  150.400332  0.430403   \n",
      "126  1.189175   8.683450  226.421603  1586.301032   66.375876  0.247943   \n",
      "127  0.673145   6.824586  367.562269  2131.106472   95.518572  0.241145   \n",
      "128  0.567823   8.811931  317.190233  2336.565192   52.750679  0.148372   \n",
      "\n",
      "           97        98        99  \n",
      "0    0.014738  0.243159  0.002732  \n",
      "1    0.016053  0.175396  0.002566  \n",
      "2    0.011251  0.220330  0.000962  \n",
      "3    0.013118  0.207655  0.002753  \n",
      "4    0.018331  0.278382  0.003960  \n",
      "..        ...       ...       ...  \n",
      "124  0.009816  0.167752  0.001010  \n",
      "125  0.011306  0.086114  0.003591  \n",
      "126  0.015495  0.197860  0.003564  \n",
      "127  0.009640  0.088668  0.002785  \n",
      "128  0.013801  0.194375  0.001691  \n",
      "\n",
      "[129 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV data into a DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('feature_data3.csv')\n",
    "\n",
    "# Convert the DataFrame to a NumPy array (matrix)\n",
    "df_data = df.values\n",
    "\n",
    "df_data = pd.DataFrame(df_data)\n",
    "\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92e0c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# import csv of lable\n",
    "df = pd.read_csv('/home/tianyu/Desktop/data_base/labels.csv')\n",
    "\n",
    "df_label = df['label'].values\n",
    "df_label_num = []\n",
    "\n",
    "for item in df_label:\n",
    "    if item == 'M':\n",
    "        df_label_num.append(1)\n",
    "    else :\n",
    "        df_label_num.append(0)\n",
    "        \n",
    "print(df_label_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3c57225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "[0.0630968  0.01787991 0.02484447 0.06768459 0.04989252 0.07851558\n",
      " 0.02923878 0.0715172  0.02233688 0.05983121 0.03739193 0.07612074\n",
      " 0.01164885 0.05899256 0.02476771 0.02909437 0.29125864 0.00701181\n",
      " 0.03014031 0.0291668  0.01441693 0.0105782  0.01764609 0.01786497\n",
      " 0.04070442 0.02864611 0.00446244 0.02767132 0.06775246 0.1120471\n",
      " 0.00506094 0.01444119 0.02027739 0.01595359 0.02719345 0.03047843\n",
      " 0.02446293 0.03794672 0.03428929 0.03004174 0.02993619 0.00643537\n",
      " 0.02293338 0.05442618 0.14655937 0.07492076 0.03201839 0.02150263\n",
      " 0.03275199 0.04322253 0.00857969 0.02660512 0.02981548 0.01689222\n",
      " 0.01141354 0.0370962  0.01075307 0.03231683 0.01425039 0.08221818\n",
      " 0.00706202 0.0418646  0.10048205 0.09602768 0.04810114 0.01567015\n",
      " 0.0282848  0.02092432 0.02672723 0.01557885 0.03456521 0.12835834\n",
      " 0.04735598 0.03840811 0.02486742 0.02193509 0.03052445 0.02686184\n",
      " 0.1755261  0.04629175 0.0203778  0.00769501 0.04072601 0.09173489\n",
      " 0.03019365 0.00768681 0.04177877 0.07893356 0.04833936 0.00948568\n",
      " 0.05109819 0.00097778 0.01913847 0.03292979 0.03104551 0.01419828\n",
      " 0.03670176 0.03543529 0.01622441 0.01286693]\n"
     ]
    }
   ],
   "source": [
    "# random forest k fold for old data and then test data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "group_models = []\n",
    "group_num = 0\n",
    "feature_importance = np.zeros(100)\n",
    "X1 = df_data.iloc[:100]\n",
    "for i in range(2):\n",
    "    kf = KFold(n_splits=5, random_state=i+1, shuffle=True)\n",
    "\n",
    "    X = df_data.iloc[0:80]\n",
    "    y = df_label_num\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=20, random_state=i+1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        if accuracy >= 0.7:\n",
    "            group_models.append(clf)\n",
    "            group_num += 1\n",
    "            \n",
    "            importances = clf.feature_importances_\n",
    "            for feature, importance in zip(X1.columns, importances):\n",
    "                feature_importance[feature] += importance\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "print(group_num)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef6bbf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0]\n",
      "final result is : \n",
      " [0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0]\n",
      "[0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "0.6190476190476191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5194/1204235807.py:15: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  vote_result = stats.mode(result_list, axis=0).mode.flatten()\n"
     ]
    }
   ],
   "source": [
    "# get test result through test data\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_task = df_data.iloc[79:100]\n",
    "result_list = []\n",
    "\n",
    "for model in group_models:\n",
    "    result = model.predict(X_task)\n",
    "    result_list.append(result)\n",
    "    print(result)\n",
    "\n",
    "vote_result = stats.mode(result_list, axis=0).mode.flatten()\n",
    "\n",
    "print(f'final result is : \\n {vote_result}')\n",
    "print(df_label_num[79:100])\n",
    "\n",
    "accuracy = accuracy_score(df_label_num[79:100], vote_result)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f6af883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1]\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "0.9\n",
      "Feature: 0, Importance: 0.0008621982306192865\n",
      "Feature: 1, Importance: 0.01122003003790211\n",
      "Feature: 2, Importance: 0.000625\n",
      "Feature: 3, Importance: 0.024319616285357934\n",
      "Feature: 4, Importance: 0.0025641025641025654\n",
      "Feature: 5, Importance: 0.026409772908036134\n",
      "Feature: 6, Importance: 0.01907094517066484\n",
      "Feature: 7, Importance: 0.005068553930397519\n",
      "Feature: 8, Importance: 0.0\n",
      "Feature: 9, Importance: 0.0012099213551119196\n",
      "Feature: 10, Importance: 0.019262018971434765\n",
      "Feature: 11, Importance: 0.010592508417899129\n",
      "Feature: 12, Importance: 0.004464410502146354\n",
      "Feature: 13, Importance: 0.0020764471565386895\n",
      "Feature: 14, Importance: 0.002227791701475911\n",
      "Feature: 15, Importance: 0.00456265271080086\n",
      "Feature: 16, Importance: 0.014245014245014237\n",
      "Feature: 17, Importance: 0.005888241691520386\n",
      "Feature: 18, Importance: 0.0\n",
      "Feature: 19, Importance: 0.013797424694829507\n",
      "Feature: 20, Importance: 0.010940918723204629\n",
      "Feature: 21, Importance: 0.008866046375701566\n",
      "Feature: 22, Importance: 0.002308802308802309\n",
      "Feature: 23, Importance: 0.010844512256418071\n",
      "Feature: 24, Importance: 0.022341501117520278\n",
      "Feature: 25, Importance: 0.00897793149473538\n",
      "Feature: 26, Importance: 0.00018896447467876024\n",
      "Feature: 27, Importance: 0.004410684600001708\n",
      "Feature: 28, Importance: 0.013497866891027643\n",
      "Feature: 29, Importance: 0.017203723594701036\n",
      "Feature: 30, Importance: 0.006923076923076914\n",
      "Feature: 31, Importance: 0.007967735589218964\n",
      "Feature: 32, Importance: 0.012259057083195721\n",
      "Feature: 33, Importance: 0.009879462967824274\n",
      "Feature: 34, Importance: 0.010409526029914205\n",
      "Feature: 35, Importance: 0.004949627623280084\n",
      "Feature: 36, Importance: 0.012454797055680006\n",
      "Feature: 37, Importance: 0.0\n",
      "Feature: 38, Importance: 0.028936724096609023\n",
      "Feature: 39, Importance: 0.005506141951137296\n",
      "Feature: 40, Importance: 0.01764177535833238\n",
      "Feature: 41, Importance: 0.0017777777777777779\n",
      "Feature: 42, Importance: 0.007774436090225566\n",
      "Feature: 43, Importance: 0.002161200101703533\n",
      "Feature: 44, Importance: 0.07361034618974019\n",
      "Feature: 45, Importance: 0.0025324469768914218\n",
      "Feature: 46, Importance: 0.016326503961241797\n",
      "Feature: 47, Importance: 0.0061739259765575556\n",
      "Feature: 48, Importance: 0.00857443609022556\n",
      "Feature: 49, Importance: 0.0038379661309010903\n",
      "Feature: 50, Importance: 0.009715399501920224\n",
      "Feature: 51, Importance: 0.002142857142857143\n",
      "Feature: 52, Importance: 0.0026048026048026045\n",
      "Feature: 53, Importance: 0.0\n",
      "Feature: 54, Importance: 0.0\n",
      "Feature: 55, Importance: 0.0\n",
      "Feature: 56, Importance: 0.002329373398555789\n",
      "Feature: 57, Importance: 0.016446369725875775\n",
      "Feature: 58, Importance: 0.006098173199445083\n",
      "Feature: 59, Importance: 0.04572213609029383\n",
      "Feature: 60, Importance: 0.014775673217778482\n",
      "Feature: 61, Importance: 0.0\n",
      "Feature: 62, Importance: 0.0071670468381314495\n",
      "Feature: 63, Importance: 0.015039058445178489\n",
      "Feature: 64, Importance: 0.013730246612567065\n",
      "Feature: 65, Importance: 0.0084536854082119\n",
      "Feature: 66, Importance: 0.0\n",
      "Feature: 67, Importance: 0.013065277446524687\n",
      "Feature: 68, Importance: 0.005502645502645502\n",
      "Feature: 69, Importance: 0.011207124449725835\n",
      "Feature: 70, Importance: 0.0038699924414210144\n",
      "Feature: 71, Importance: 0.022469729406487986\n",
      "Feature: 72, Importance: 0.0371579334544309\n",
      "Feature: 73, Importance: 0.008382917641229665\n",
      "Feature: 74, Importance: 0.004212106749393471\n",
      "Feature: 75, Importance: 0.0\n",
      "Feature: 76, Importance: 0.0018096999383549104\n",
      "Feature: 77, Importance: 0.00370599014218381\n",
      "Feature: 78, Importance: 0.00015289818509854643\n",
      "Feature: 79, Importance: 0.019084178167171607\n",
      "Feature: 80, Importance: 0.0\n",
      "Feature: 81, Importance: 0.002131578947368421\n",
      "Feature: 82, Importance: 0.0\n",
      "Feature: 83, Importance: 0.009775631091420555\n",
      "Feature: 84, Importance: 0.032227771466680974\n",
      "Feature: 85, Importance: 0.009373049202512359\n",
      "Feature: 86, Importance: 0.020104328595377186\n",
      "Feature: 87, Importance: 0.0012698412698412698\n",
      "Feature: 88, Importance: 0.033565299503248894\n",
      "Feature: 89, Importance: 0.007162266376509655\n",
      "Feature: 90, Importance: 0.014030767520553034\n",
      "Feature: 91, Importance: 0.0049957760882130605\n",
      "Feature: 92, Importance: 0.004772688533372296\n",
      "Feature: 93, Importance: 0.02127569776173467\n",
      "Feature: 94, Importance: 0.024907508907591504\n",
      "Feature: 95, Importance: 0.00583907196237254\n",
      "Feature: 96, Importance: 0.003241427884285026\n",
      "Feature: 97, Importance: 0.01281569421004079\n",
      "Feature: 98, Importance: 0.0\n",
      "Feature: 99, Importance: 0.009921718584415101\n"
     ]
    }
   ],
   "source": [
    "# random forest for old data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df_data.iloc[0:100]\n",
    "y = df_label_num\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20, random_state=110)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "for feature, importance in zip(X.columns, importances):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eab75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyradiomics] *",
   "language": "python",
   "name": "conda-env-pyradiomics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
